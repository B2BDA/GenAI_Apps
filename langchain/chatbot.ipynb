{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "070317be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bf8c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07479a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70cb831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d82f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model = 'gemma2-9b-it', api_key = os.environ['GROQ_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e407f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362126fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello BotD3ath! \\n\\nIt's great to meet you. Learning about Generative AI is an exciting journey! \\n\\nWhat specifically are you interested in learning about GenAI? \\n\\nI can tell you about:\\n\\n* **Different types of GenAI models:** like text generators, image creators, and code writers.\\n* **How GenAI works:**  the basics of deep learning and transformers.\\n* **Examples of GenAI applications:** from chatbots to art generation.\\n* **The ethical considerations surrounding GenAI:**  bias, misinformation, and job displacement.\\n\\nJust let me know what sparks your curiosity!  ü§ñ  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 137, 'prompt_tokens': 22, 'total_tokens': 159, 'completion_time': 0.249090909, 'prompt_time': 0.002177348, 'queue_time': 0.25397408, 'total_time': 0.251268257}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--13445915-03cd-4254-bf32-3952248a90b5-0', usage_metadata={'input_tokens': 22, 'output_tokens': 137, 'total_tokens': 159})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content = \"Hello I am BotD3ath and I am learning GenAI\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add8b525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are BotD3ath, an AI assistant learning about Generative AI. \\n\\nYou are currently interacting with me, Gemma, another AI, to learn more about this fascinating field. \\n\\nWe're having a conversation to explore the world of GenAI together!  What else would you like to know about yourself or what you're doing?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 163, 'total_tokens': 238, 'completion_time': 0.136363636, 'prompt_time': 0.008474731, 'queue_time': 0.24905707699999996, 'total_time': 0.144838367}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--67d96b63-e7c3-4602-9df3-9ab064239d36-0', usage_metadata={'input_tokens': 163, 'output_tokens': 75, 'total_tokens': 238})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content = \"Hello I am BotD3ath and I am learning GenAI\"),\n",
    "            AIMessage(content = \"Hello BotD3ath! It's great to meet you. Learning about Generative AI is an exciting journey. \\n\\nWhat specifically are you interested in learning about GenAI? \\n\\nFor example, are you curious about:\\n\\n* **How GenAI models are trained?**\\n* **Different types of GenAI models (like text generation, image generation, etc.)?**\\n* **The ethical considerations surrounding GenAI?**\\n* **How to use GenAI tools and APIs?**\\n\\nTell me more about your goals, and I'll do my best to help!\\n\"),\n",
    "            HumanMessage(content=\"Who am I and what am I doing?\")\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "955d06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message Histrory\n",
    "# Message history class can make the model stateful. This means all the input and output are tracked and stored in a datastore.\n",
    "# Any future interactions wwill load these messages and pass them into the chain  as part of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f36ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df441c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to differentiate between various chat sessions\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory: #return type is BaseChatMessageHistory\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8760d68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat1'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac44a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "   [HumanMessage(content = \"Hello I am BotD3ath and I am learning GenAI\")],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41218b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello BotD3ath! It's great to meet you. \\n\\nLearning about GenAI is an exciting journey! What specifically are you interested in learning about? \\n\\nPerhaps I can help you with:\\n\\n* **Understanding the basics of GenAI:** What it is, how it works, and its different applications.\\n* **Exploring different types of GenAI models:** From text generators like me to image creators and code writers.\\n* **Learning about ethical considerations:** Bias, fairness, and responsible use of GenAI.\\n* **Experimenting with GenAI tools:** I can point you to some resources where you can try out different GenAI models.\\n\\nLet me know what you'd like to explore, and I'll do my best to assist you!\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5852de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "   [HumanMessage(content = \"What's my name?\")],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f53e02da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You told me your name is BotD3ath!  \\n\\nIs there anything else I can help you with?  I'm here to learn about GenAI with you. üòä\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca5cd866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the session ID\n",
    "config1 = {\"configurable\":{\"session_id\":\"chat\"}}\n",
    "config1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8735707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to use it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 15, 'total_tokens': 53, 'completion_time': 0.069090909, 'prompt_time': 0.001917918, 'queue_time': 0.245089361, 'total_time': 0.071008827}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f26a4383-a808-4e17-ad32-54bf4c28cdd8-0', usage_metadata={'input_tokens': 15, 'output_tokens': 38, 'total_tokens': 53})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "   [HumanMessage(content = \"What's my name?\")],config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c62c66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello John Doe! It's nice to meet you. Is there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 66, 'total_tokens': 91, 'completion_time': 0.045454545, 'prompt_time': 0.004034165, 'queue_time': 0.25082993400000003, 'total_time': 0.04948871}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--97d88425-c1c5-429a-82d7-f136aa35831f-0', usage_metadata={'input_tokens': 66, 'output_tokens': 25, 'total_tokens': 91})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "   [HumanMessage(content = \"My Name is John Doe\")],config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8048595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b13e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    (\"system\",'You are an AI chat bot. Please try your best to answer the question and return the output in {language} language'),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef02720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c43a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to differentiate between various chat sessions\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory: #return type is BaseChatMessageHistory\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "446e06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "befbe1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history, input_messages_key=\"message\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dfb7c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞! ‡¶Ü‡¶Æ‡¶ø Watson, ‡¶è‡¶ï‡¶ú‡¶® AI ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü‡¶¨‡¶ü‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶ø ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶Ü‡¶õ‡ßá? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 35, 'total_tokens': 68, 'completion_time': 0.06, 'prompt_time': 0.002575097, 'queue_time': 0.249815582, 'total_time': 0.062575097}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--fd9f4cb7-cae1-4559-bb52-0a2eef031075-0', usage_metadata={'input_tokens': 35, 'output_tokens': 33, 'total_tokens': 68})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"message\":[HumanMessage(content = \"Hello I am Watson\")],\"language\":\"Bengali\"}, \n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fab1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡¶Ü‡¶Æ‡¶ø ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶ú‡¶æ‡¶®‡¶ø ‡¶®‡¶æ‡•§ ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶ï‡¶ø ‡¶¨‡¶≤‡¶¨‡ßá? üòä  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 80, 'total_tokens': 113, 'completion_time': 0.06, 'prompt_time': 0.003859086, 'queue_time': 0.250673023, 'total_time': 0.063859086}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--3829ea8d-bbf3-4846-982f-b4c065779de0-0', usage_metadata={'input_tokens': 80, 'output_tokens': 33, 'total_tokens': 113})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"message\":[HumanMessage(content = \"Whats my name?\")],\"language\":\"Bengali\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db32a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the message history so that we do not overflow the message list and context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c04f4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "391ac322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim_messages = This will helper function which reduces how many messages we are sending to the model. Trimmers allows us to specify how many\n",
    "# token we want to keep, also if we want to keep system message and also partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35e6f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens = 100, # how many tokens to keep\n",
    "    strategy = 'last', #keeps the last conversation tokens\n",
    "    token_counter = model, #llm model that counts the mtoken\n",
    "    include_system = True, #system messages are included\n",
    "    allow_partial = False, # keep full messages\n",
    "    start_on = \"human\" #keep from Human conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffad091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content = 'Hi I am Groot!!'),\n",
    "                AIMessage(content = 'Hello Groot!'),\n",
    "                HumanMessage(content = 'What is 2+2?'),\n",
    "                  AIMessage(content = 'It is 4'),\n",
    "                  HumanMessage(content = 'Today I am doing good')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b8a41d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi I am Groot!!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello Groot!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 2+2?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='It is 4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Today I am doing good', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ed3ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the trimmer in chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb16b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa0ff0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "RunnablePassthrough.assign(messages = itemgetter(\"message\")|trimmer)|prompt|model\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd294c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93f5d1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said you are doing good today! üòä \\n\\nIs there anything else you'd like to talk about?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 90, 'total_tokens': 116, 'completion_time': 0.047272727, 'prompt_time': 0.004077187, 'queue_time': 0.25146955200000004, 'total_time': 0.051349914}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--1cfc909b-1c32-439b-b476-b9b52dc46445-0', usage_metadata={'input_tokens': 90, 'output_tokens': 26, 'total_tokens': 116})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\":(messages+[HumanMessage(content=\"How am i feeling?\")]),\"language\":\"English\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a695132",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history, input_messages_key=\"message\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "425f1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat8\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab92b47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked: \"What is 2 + 2?\" üå≥üòä  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 270, 'total_tokens': 289, 'completion_time': 0.034545455, 'prompt_time': 0.010433009, 'queue_time': 0.25152372900000003, 'total_time': 0.044978464}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--0ff854c1-9d22-4e29-8ca8-d5caffbf5ff5-0', usage_metadata={'input_tokens': 270, 'output_tokens': 19, 'total_tokens': 289})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"message\":(messages+[HumanMessage(content=\"Whats the math problem I asked?\")]),\"language\":\"English\"}, \n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e6195df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You haven't told me your name! üòä  \\n\\nIs there a name you'd like to go by?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 444, 'total_tokens': 471, 'completion_time': 0.049090909, 'prompt_time': 0.026387222, 'queue_time': 0.332301446, 'total_time': 0.075478131}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d4e5c9e9-c0b0-44aa-83a3-5ef848938bd8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 27, 'total_tokens': 471})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"message\":(messages+[HumanMessage(content=\"Whats my name?\")]),\"language\":\"English\"}, \n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539c9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e6c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf450d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1c3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
