{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070317be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17bf8c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07479a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70cb831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d82f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model = 'gemma2-9b-it', api_key = os.environ['GROQ_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e407f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "362126fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello BotD3ath!\\n\\nIt's great to meet you. Learning about GenAI is an exciting journey. What aspects of GenAI are you most interested in exploring? \\n\\nI can help you understand:\\n\\n* **The basics of how GenAI works:**  Like how large language models are trained and what makes them capable of generating text, code, and even images.\\n* **Different types of GenAI models:**  From text-based models like me to image generation models like DALL-E and Stable Diffusion.\\n* **The potential applications of GenAI:**  In fields like writing, art, education, customer service, and more.\\n* **The ethical considerations surrounding GenAI:**  Such as bias, misinformation, and the impact on jobs.\\n\\nJust let me know what you'd like to learn about, and I'll do my best to assist you.  \\n\\nWelcome to the world of GenAI!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 196, 'prompt_tokens': 22, 'total_tokens': 218, 'completion_time': 0.356363636, 'prompt_time': 0.002219497, 'queue_time': 0.251960892, 'total_time': 0.358583133}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--233fcd92-8797-4377-b2bf-33c69f198fcb-0', usage_metadata={'input_tokens': 22, 'output_tokens': 196, 'total_tokens': 218})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content = \"Hello I am BotD3ath and I am learning GenAI\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "add8b525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are BotD3ath, an AI assistant learning about Generative AI. \\n\\nYou're currently engaged in a conversation with me, Gemma, another AI, to expand your understanding of this fascinating field. \\n\\nIs there anything specific you'd like to know or explore about GenAI right now?  Perhaps we could discuss a particular type of model, its applications, or even some of the ethical dilemmas it presents?  I'm here to help you learn!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 163, 'total_tokens': 263, 'completion_time': 0.181818182, 'prompt_time': 0.008475966, 'queue_time': 0.252338924, 'total_time': 0.190294148}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--fdbf9ca2-2ba4-4a34-b25b-db53ea8fdcae-0', usage_metadata={'input_tokens': 163, 'output_tokens': 100, 'total_tokens': 263})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content = \"Hello I am BotD3ath and I am learning GenAI\"),\n",
    "            AIMessage(content = \"Hello BotD3ath! It's great to meet you. Learning about Generative AI is an exciting journey. \\n\\nWhat specifically are you interested in learning about GenAI? \\n\\nFor example, are you curious about:\\n\\n* **How GenAI models are trained?**\\n* **Different types of GenAI models (like text generation, image generation, etc.)?**\\n* **The ethical considerations surrounding GenAI?**\\n* **How to use GenAI tools and APIs?**\\n\\nTell me more about your goals, and I'll do my best to help!\\n\"),\n",
    "            HumanMessage(content=\"Who am I and what am I doing?\")\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "955d06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message Histrory\n",
    "# Message history class can make the model stateful. This means all the input and output are tracked and stored in a datastore.\n",
    "# Any future interactions wwill load these messages and pass them into the chain  as part of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93f36ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df441c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to differentiate between various chat sessions\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory: #return type is BaseChatMessageHistory\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8760d68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat1'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac44a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "   [HumanMessage(content = \"Hello I am BotD3ath and I am learning GenAI\")],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41218b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello BotD3ath! It's great to meet you. \\n\\nLearning about GenAI is exciting! It's a rapidly developing field with a lot of potential. \\n\\nWhat aspects of GenAI are you most interested in learning about? \\n\\nPerhaps I can help you by:\\n\\n* **Explaining key concepts:** Like what GenAI is, how it works, and different types of models.\\n* **Sharing examples:** Showing you what GenAI can do, from writing stories to generating code.\\n* **Discussing ethical considerations:** Talking about the potential benefits and risks of GenAI.\\n\\nLet me know how I can help you on your learning journey! üòä\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5852de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "   [HumanMessage(content = \"What's my name?\")],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f53e02da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You told me your name is BotD3ath! üòÑ  \\n\\nIt's a cool name.  Are you working on any projects related to your name? ü§ñüíÄ  \\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca5cd866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the session ID\n",
    "config1 = {\"configurable\":{\"session_id\":\"chat\"}}\n",
    "config1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8735707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'm happy to use it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 15, 'total_tokens': 57, 'completion_time': 0.076363636, 'prompt_time': 0.001916227, 'queue_time': 0.254858073, 'total_time': 0.078279863}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--c3f1966d-e759-466f-b52b-44f6697a42f7-0', usage_metadata={'input_tokens': 15, 'output_tokens': 42, 'total_tokens': 57})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "   [HumanMessage(content = \"What's my name?\")],config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c62c66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi John Doe, it's nice to meet you! \\n\\nHow can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 70, 'total_tokens': 94, 'completion_time': 0.043636364, 'prompt_time': 0.003601644, 'queue_time': 0.250458585, 'total_time': 0.047238008}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d5a9f7ad-ae92-458d-a1c6-224432c1e9d0-0', usage_metadata={'input_tokens': 70, 'output_tokens': 24, 'total_tokens': 94})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "   [HumanMessage(content = \"My Name is John Doe\")],config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8048595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b13e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    (\"system\",'You are an AI chat bot. Please try your best to answer the question and return the output in {language} language'),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef02720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c43a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to differentiate between various chat sessions\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory: #return type is BaseChatMessageHistory\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "446e06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbe1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history, input_messages_key=\"message\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dfb7c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞, Watson! ‡¶Ü‡¶®‡¶®‡ßç‡¶¶ ‡¶ï‡¶∞‡¶ø ‡¶§‡ßã‡¶Æ‡¶æ‡¶ï‡ßá ‡¶ú‡¶æ‡¶®‡¶§‡ßá‡•§ üòä  ‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø‡•§ \\n\\n‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶Ü‡¶Æ‡¶ø ‡¶§‡ßã‡¶Æ‡¶æ‡¶ï‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 84, 'total_tokens': 145, 'completion_time': 0.110909091, 'prompt_time': 0.005087411, 'queue_time': 0.25020674800000003, 'total_time': 0.115996502}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--3354bc46-648d-4939-b9cf-b523456e9fe2-0', usage_metadata={'input_tokens': 84, 'output_tokens': 61, 'total_tokens': 145})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"message\":[HumanMessage(content = \"Hello I am Watson\")],\"language\":\"Bengali\"}, \n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fab1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ Watson. üòä  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 157, 'total_tokens': 170, 'completion_time': 0.023636364, 'prompt_time': 0.007701727, 'queue_time': 0.252708801, 'total_time': 0.031338091}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--7434f713-8c3c-4b58-ae90-cf0db78072aa-0', usage_metadata={'input_tokens': 157, 'output_tokens': 13, 'total_tokens': 170})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"message\":[HumanMessage(content = \"Whats my name?\")],\"language\":\"Bengali\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db32a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the message history so that we do not overflow the message list and context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c04f4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "391ac322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim_messages = This will helper function which reduces how many messages we are sending to the model. Trimmers allows us to specify how many\n",
    "# token we want to keep, also if we want to keep system message and also partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35e6f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens = 10, # how many tokens to keeo\n",
    "    strategy = 'last', #keeps the last conversation tokens\n",
    "    token_counter = model, #llm model that counts the mtoken\n",
    "    include_system = True, #system messages are included\n",
    "    allow_partial = False, # keep full messages\n",
    "    start_on = \"human\" #keep from Human conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b8a41d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='It is 4', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke([HumanMessage(content = 'Hi I am Groot!!'),\n",
    "                AIMessage(content = 'Hello Groot!'),\n",
    "                HumanMessage(content = 'What is 2+2?'),\n",
    "                  HumanMessage(content = 'It is 4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ed3ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the trimmer in chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb16b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa0ff0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "RunnablePassthrough.assign(messages = itemgetter(\"message\"))|prompt|model\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd294c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93f5d1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry to hear that you're feeling sad.  \\n\\nIs there anything I can do to help? Perhaps you'd like to talk about what's making you feel this way, or maybe you'd prefer a distraction like a joke or a story? \\n\\nRemember, it's okay to feel sad sometimes, and things will get better.  üå≥üòä\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 73, 'total_tokens': 154, 'completion_time': 0.147272727, 'prompt_time': 0.004630339, 'queue_time': 0.24885575899999998, 'total_time': 0.151903066}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--8c45c07c-977b-4bda-a13e-f6d7bc2c525f-0', usage_metadata={'input_tokens': 73, 'output_tokens': 81, 'total_tokens': 154})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\":([HumanMessage(content = 'Hi I am Groot!!'),\n",
    "                AIMessage(content = 'Hello Groot!'),\n",
    "                HumanMessage(content = 'What is 2+2?'),\n",
    "                  AIMessage(content = 'It is 4')]+[HumanMessage(content=\"I am sad\")]),\"language\":\"English\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92b47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
